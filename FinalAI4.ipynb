{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c54aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of text: <class 'str'>\n",
      "Text content:\n",
      " QVC Network Inc. said it completed its acquisition of CVN Cos. for about $ 423 million .\n",
      "The spirits , of course , could hardly care less whether people do or do n't believe in them .\n",
      "The debt ceiling is scheduled to fall to $ 2.8 trillion from $ 2.87 trillion at midnight tonight .\n",
      "\n",
      "\n",
      "Length of the text: 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admine\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of sentences: 3\n",
      "Number of words: 56\n",
      "Tokenized words: ['QVC', 'Network', 'Inc.', 'said', 'it', 'completed', 'its', 'acquisition', 'of', 'CVN', 'Cos.', 'for', 'about', '$', '423', 'million', '.', 'The', 'spirits', ',', 'of', 'course', ',', 'could', 'hardly', 'care', 'less', 'whether', 'people', 'do', 'or', 'do', \"n't\", 'believe', 'in', 'them', '.', 'The', 'debt', 'ceiling', 'is', 'scheduled', 'to', 'fall', 'to', '$', '2.8', 'trillion', 'from', '$', '2.87', 'trillion', 'at', 'midnight', 'tonight', '.']\n",
      "\n",
      "Top 10 most common tokens (including punctuation):\n",
      "[('$', 3), ('.', 3), ('of', 2), ('The', 2), (',', 2), ('do', 2), ('to', 2), ('trillion', 2), ('QVC', 1), ('Network', 1)]\n",
      "\n",
      "Words after removing punctuation: ['QVC', 'Network', 'Inc.', 'said', 'it', 'completed', 'its', 'acquisition', 'of', 'CVN', 'Cos.', 'for', 'about', '423', 'million', 'The', 'spirits', 'of', 'course', 'could', 'hardly', 'care', 'less', 'whether', 'people', 'do', 'or', 'do', \"n't\", 'believe', 'in', 'them', 'The', 'debt', 'ceiling', 'is', 'scheduled', 'to', 'fall', 'to', '2.8', 'trillion', 'from', '2.87', 'trillion', 'at', 'midnight', 'tonight']\n",
      "\n",
      "Stopwords list (sample): ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
      "\n",
      "Cleaned words (no stopwords): ['QVC', 'Network', 'Inc.', 'said', 'completed', 'acquisition', 'CVN', 'Cos.', '423', 'million', 'spirits', 'course', 'could', 'hardly', 'care', 'less', 'whether', 'people', \"n't\", 'believe', 'debt', 'ceiling', 'scheduled', 'fall', '2.8', 'trillion', '2.87', 'trillion', 'midnight', 'tonight']\n",
      "Number of cleaned words: 30\n",
      "\n",
      "Top 10 most common cleaned words:\n",
      "[('trillion', 2), ('QVC', 1), ('Network', 1), ('Inc.', 1), ('said', 1), ('completed', 1), ('acquisition', 1), ('CVN', 1), ('Cos.', 1), ('423', 1)]\n",
      "\n",
      "ðŸ”¹ Part of Speech (POS) Tagging:\n",
      "QVC: NNP\n",
      "Network: NNP\n",
      "Inc.: NNP\n",
      "said: VBD\n",
      "completed: VBN\n",
      "acquisition: NN\n",
      "CVN: NNP\n",
      "Cos.: NNP\n",
      "423: CD\n",
      "million: CD\n",
      "spirits: NNS\n",
      "course: NN\n",
      "could: MD\n",
      "hardly: RB\n",
      "care: VB\n",
      "less: RBR\n",
      "whether: IN\n",
      "people: NNS\n",
      "n't: RB\n",
      "believe: VB\n",
      "debt: NN\n",
      "ceiling: NN\n",
      "scheduled: VBN\n",
      "fall: NN\n",
      "2.8: CD\n",
      "trillion: CD\n",
      "2.87: CD\n",
      "trillion: CD\n",
      "midnight: NN\n",
      "tonight: NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Read and Load the Text File\n",
    "text_file = open(\"sentences.txt\")\n",
    "text = text_file.read()\n",
    "\n",
    "print(\"Data type of text:\", type(text))\n",
    "print(\"Text content:\\n\", text)\n",
    "print(\"\\nLength of the text:\", len(text))\n",
    "\n",
    "# Import Required Libraries and Download NLTK Resources\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')  # Needed for POS tagging\n",
    "\n",
    "# Sentence and Word Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"\\nNumber of sentences:\", len(sentences))\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(\"Number of words:\", len(words))\n",
    "print(\"Tokenized words:\", words)\n",
    "\n",
    "# Frequency Distribution of All Words (including punctuation)\n",
    "fdist_all = FreqDist(words)\n",
    "print(\"\\nTop 10 most common tokens (including punctuation):\")\n",
    "print(fdist_all.most_common(10))\n",
    "\n",
    "# Remove Punctuation\n",
    "#string.punctuation is a built-in string in Python that contains all standard punctuation characters\n",
    "words_no_punc = [w for w in words if w not in string.punctuation] #if w not in string.punctuation only it will be included\n",
    "print(\"\\nWords after removing punctuation:\", words_no_punc)\n",
    "\n",
    "#Remove Stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "print(\"\\nStopwords list (sample):\", stopwords_list[:10])  # Show only first 10 \n",
    "\n",
    "clean_words = [w for w in words_no_punc if w.lower() not in stopwords_list]\n",
    "#converts each word to lowercase so comparison with stopwords is case-insensitive.\n",
    "print(\"\\nCleaned words (no stopwords):\", clean_words)\n",
    "print(\"Number of cleaned words:\", len(clean_words))\n",
    "\n",
    "# Frequency Distribution of Cleaned Words\n",
    "fdist_clean = FreqDist(clean_words)\n",
    "print(\"\\nTop 10 most common cleaned words:\")\n",
    "print(fdist_clean.most_common(10))\n",
    "\n",
    "# POS Tagging\n",
    "pos_tags = pos_tag(clean_words)\n",
    "print(\"\\nðŸ”¹ Part of Speech (POS) Tagging:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c0071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
